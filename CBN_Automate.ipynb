{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "CBN_Automate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6nYNNtIqfFE",
        "outputId": "4ed5babe-be39-4dac-ffb0-2ee1833c009d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "l6nYNNtIqfFE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plain-china",
        "outputId": "21c97324-4d3e-487f-b27b-9e6e32b40132"
      },
      "source": [
        "import sys \n",
        "sys.path.insert(0, '/content/drive/MyDrive/CBN_Automate')\n",
        "%cd /content/drive/MyDrive/CBN_Automate\n",
        "\n",
        "import pandas as pd\n",
        "import Resource  as res\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import gspread\n",
        "import gspread_dataframe as gd\n",
        "from googleapiclient import discovery\n",
        "import psycopg2\n",
        "import psycopg2.extras as extras\n",
        "\n",
        "connection = psycopg2.connect(user=\"postgres\",\n",
        "                              password=\"smartsetter\",\n",
        "                              host=\"ss-db-data-dev.cpeist8s9qou.us-west-2.rds.amazonaws.com\",\n",
        "                              port=\"5432\",\n",
        "                              database=\"postgres\")\n",
        "\n",
        "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name(\"/content/drive/MyDrive/CBN_Automate/cbn-file-Automate.json\",scope)\n",
        "service = discovery.build('sheets', 'v4', credentials=credentials)"
      ],
      "id": "plain-china",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CBN_Automate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maritime-valentine"
      },
      "source": [
        "#finding mobile numbers using name\n",
        "def finding_mobile_name(name,state, ph):\n",
        "    \n",
        "    \n",
        "    if ph == None:\n",
        "        \n",
        "        if str(name).lower() != 'nan' and str(state).lower() != 'nan':\n",
        "            name_file = globals()[f\"{state}\"][globals()[f\"{state}\"][\"name\"]==name]\n",
        "            if len(name_file) > 0:\n",
        "                name_file = name_file.reset_index(drop = True)\n",
        "                for name_index , manual_name in enumerate(name_file[\"name\"]):\n",
        "                    if str(name).lower() == str(manual_name).lower():\n",
        "                        if str(name_file.loc[name_index,'phone'])[0] == '1' and len(str(name_file.loc[name_index,'phone'])) < 11:\n",
        "                            return None\n",
        "                        else:\n",
        "                            return name_file.loc[name_index,'phone']\n",
        "\n",
        "    else:\n",
        "        return ph\n",
        "    \n",
        "#finding mobile numbers using email\n",
        "def finding_mobile_email(email, state, ph):\n",
        "    \n",
        "    if ph == None:\n",
        "        if str(email).lower() != 'nan'and str(state).lower() != 'nan':\n",
        "            email_file = globals()[f\"{state}\"][globals()[f\"{state}\"][\"email\"]==email]\n",
        "            if len(email_file) > 0:\n",
        "                email_file = email_file.reset_index(drop = True)\n",
        "                \n",
        "                for email_index , manual_email in enumerate(email_file[\"email\"]):\n",
        "                    if str(email).lower() == str(manual_email).lower():\n",
        "                        if str(email_file.loc[email_index,'phone'])[0] == '1' and len(str(email_file.loc[email_index,'phone'])) < 11:\n",
        "                            return None\n",
        "                        else:\n",
        "                            return email_file.loc[email_index,'phone']\n",
        "            \n",
        "    else:\n",
        "        return ph\n",
        "    \n",
        "# #finding mobile numbers using name\n",
        "# def finding_mobile_name(name, state, ph , Zip):\n",
        "    \n",
        "\n",
        "#     if ph == None and str(Zip).lower()!='nan' and Zip != None and str(state).lower() != 'nan':\n",
        "        \n",
        "#         Zip = str(Zip).replace(\".0\",\"\")\n",
        "#         Zip_file =  globals()[f\"{state}\"][globals()[f\"{state}\"][\"zip\"] == str(Zip)]    \n",
        "#         Zip_file.reset_index(drop = True , inplace = True)\n",
        "        \n",
        "#         if str(name).lower() != 'nan' and str(state).lower() != 'nan':\n",
        "#             for name_index , manual_name in enumerate(Zip_file[\"name\"]):\n",
        "#                 if str(name).lower() == str(manual_name).lower():\n",
        "#                     return Zip_file.loc[name_index,'phone']\n",
        "            \n",
        "#     else:\n",
        "#         return ph\n",
        "    \n",
        "# #finding mobile numbers using name\n",
        "# def finding_mobile_email(email, state, ph , Zip):\n",
        "    \n",
        "#     if ph == None and str(Zip).lower() != 'nan' and Zip != None and str(state).lower() != 'nan':\n",
        "        \n",
        "#         Zip = str(Zip).replace(\".0\",\"\")\n",
        "#         Zip_file =  globals()[f\"{state}\"][globals()[f\"{state}\"][\"zip\"]== str(Zip)]    \n",
        "#         Zip_file.reset_index(drop = True , inplace = True)\n",
        "        \n",
        "#         if str(email).lower() != 'nan'and str(state).lower() != 'nan':\n",
        "#             for email_index , manual_email in enumerate(Zip_file[\"email\"]):\n",
        "#                 if str(email).lower() == str(manual_email).lower():\n",
        "#                     return Zip_file.loc[email_index,'phone']\n",
        "            \n",
        "#     else:\n",
        "#         return ph"
      ],
      "id": "maritime-valentine",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "distant-technology"
      },
      "source": [
        "###  Input URL'S"
      ],
      "id": "distant-technology"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wireless-couple"
      },
      "source": [
        "### Input file Url \n",
        "urls = [\"https://docs.google.com/spreadsheets/d/1xPv4ihEPT8ViJeeNFfPnxrQFc5QAqRk79OS4aCiC0Dk/edit?urlBuilderDomain=smartsetter.io#gid=1367061075\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1VGxx3f8-wf0X2RaRh7-LQDiiEWBt5caPlp0ytjNPD4E/edit#gid=1844540345\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1Bv8fU8O-m6exp7QoqUn1fGUp3dd-lCKFYbQD7KY9Lq0/edit?urlBuilderDomain=smartsetter.io#gid=307053804\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1AvUaLkzRxksWb4IuFjWD_3NTlqMB--0ow0YYQ0DTrJM/edit?urlBuilderDomain=smartsetter.io#gid=228921234\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1R4T7G5-I6hkOcNBXovokeJLewNSpgU1mpMAb0x9GOlk/edit?urlBuilderDomain=smartsetter.io#gid=246111282\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1UhAUW_3jr3aWMZtlybIKH_MYLYWKe2xChMXPlj-hcWI/edit?urlBuilderDomain=smartsetter.io#gid=1696486497\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1GXy2pdYhbuyku2wQjrVMbfwJr7nccdt5_mZ1V_PteRM/edit?urlBuilderDomain=smartsetter.io#gid=382055332\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1Enaz3MGTjQgcSFGyBgc5YlFMz1n4HBvv727GW8JDxq8/edit?urlBuilderDomain=smartsetter.io#gid=1499399556\",\n",
        "        \"https://docs.google.com/spreadsheets/d/11XWc7INBjz4cjjx_HGrn1Si1wIkODMhCZ7QkpQINxS0/edit#gid=1599873396\",\n",
        "        \"https://docs.google.com/spreadsheets/d/18qNlTM-XhgId_hkkXFynWLpvHOzlVPXJM9cnbI52_Cw/edit?urlBuilderDomain=smartsetter.io#gid=223003133\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1I4RjcUzyCSmVmrJki40CmLBqMg-JmhS15saNcfi0ykU/edit?urlBuilderDomain=smartsetter.io#gid=923403582\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1o0AFjVAqC41BJZfeme90i-xve7jB_xA-864-ah4L3pU/edit?urlBuilderDomain=smartsetter.io#gid=752426163\",\n",
        "        \"https://docs.google.com/spreadsheets/d/12JA_Bjrt-NHxb_01GPAOKPlG0wbOcMgeGE6bjh7_Ixw/edit?urlBuilderDomain=smartsetter.io#gid=1989394655\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1up3wlvKkQVwb4rolgm-OWXA4Brcvby1SJOv2VFfFZo8/edit?urlBuilderDomain=smartsetter.io#gid=1921068393\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1GoGL6F-HjGxhJX3tm8Mssigw2RmqenJ0vcpNY7DBG0A/edit?urlBuilderDomain=smartsetter.io#gid=894022260\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1iwETBuI5YgOwWjn5r564jcvTIElfULZ4lHHkZPceGJ0/edit?urlBuilderDomain=smartsetter.io#gid=1412264867\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1TvtahaiS4JWkz-MHop4FmGviepBO1Eu7dTHDLIbON3E/edit?urlBuilderDomain=smartsetter.io#gid=347822419\",\n",
        "        \"https://docs.google.com/spreadsheets/d/1FWpo01xJpIfWwx4yIW2S1evl4PSDcY1n6loBmuq3M9g/edit?urlBuilderDomain=smartsetter.io#gid=741166654\"]\n"
      ],
      "id": "wireless-couple",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_k59VZn4UvK"
      },
      "source": [
        ""
      ],
      "id": "R_k59VZn4UvK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "human-twins"
      },
      "source": [
        "#urls = [\"https://docs.google.com/spreadsheets/d/1mwa8slB8eZQTF6cS5bCEoCfGF8QeSA8w_lexb3Wi0vE/edit#gid=260483104\"]"
      ],
      "id": "human-twins",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "russian-portal"
      },
      "source": [
        "#To get spreadsheet informations like spreadsheet file name and sheet name\n",
        "spreadsheet_id = []\n",
        "sheet_id = []\n",
        "file_name = []\n",
        "sheet_name = []\n",
        "for sid in urls:\n",
        "    spread_id = sid.split('/')\n",
        "    spreadsheet_id.append(spread_id[5])\n",
        "    sh_id = sid.split('=')\n",
        "    sheet_id.append(sh_id[-1])\n",
        "    sheet_metadata = service.spreadsheets().get(spreadsheetId=spread_id[5]).execute()\n",
        "    file_name.append(sheet_metadata.get('properties').get('title'))\n",
        "    properties = sheet_metadata.get('sheets')\n",
        "    \n",
        "    for  item in properties:\n",
        "        if item.get(\"properties\").get('sheetId') == int(sh_id[-1]):\n",
        "            sh_name = (item.get(\"properties\").get('title'))\n",
        "            sheet_name.append(sh_name)"
      ],
      "id": "russian-portal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "excellent-snapshot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0904428d-d4cd-41fe-d6fd-0ad4cdd91d0d"
      },
      "source": [
        "#For reading all the files and creating dynamic variable for each dataframe\n",
        "column_length = []\n",
        "for url in range(len(urls)):\n",
        "    \n",
        "    globals()[f\"df{url}\"] = res.read_dataframe(urls[url])\n",
        "    \n",
        "    print(globals()[f\"df{url}\"].shape)\n",
        "    column_length.append(globals()[f\"df{url}\"].shape[1])\n",
        "    globals()[f\"df{url}\"][\"Full_Name\"] = None\n",
        "    globals()[f\"df{url}\"][\"Found_Mobile\"] = None\n",
        "    globals()[f\"df{url}\"][\"Assign\"]  = None \n",
        "    #globals()[f\"df{url}\"][\"Comments\"]  = None "
      ],
      "id": "excellent-snapshot",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1524, 15)\n",
            "(1541, 15)\n",
            "(1238, 15)\n",
            "(1008, 15)\n",
            "(3729, 15)\n",
            "(4893, 15)\n",
            "(2561, 15)\n",
            "(1215, 15)\n",
            "(6503, 15)\n",
            "(2250, 15)\n",
            "(1415, 15)\n",
            "(6952, 15)\n",
            "(3300, 15)\n",
            "(2336, 15)\n",
            "(7506, 15)\n",
            "(2363, 15)\n",
            "(4023, 15)\n",
            "(2807, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "common-pollution",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be3e363-b9a4-4740-e380-78ee52fc8906"
      },
      "source": [
        "#finding all unique states and creating state file #extracting state file from DB\n",
        "cursor = connection.cursor()\n",
        "state = []\n",
        "\n",
        "for url in range(len(urls)):\n",
        "    \n",
        "    print(\"\\nTaking state name for file name --->  \", file_name[url], \"sheet name -->\", sheet_name[url])\n",
        "    find_state = res.state_finder(globals()[f\"df{url}\"].columns)\n",
        "    if len(find_state) != 0:\n",
        "        for uniq_state in  globals()[f\"df{url}\"][find_state].unique():\n",
        "            if uniq_state not in state:\n",
        "                if str(uniq_state).lower()!= 'nan':\n",
        "                    state.append(uniq_state)\n",
        "    else:\n",
        "        print(\"couldn't find state column in this file no : \", url)\n",
        "for st in state:\n",
        "    \n",
        "    postgreSQL_select_Query = 'select * from \"manual_staging\" where \"state\" = '+\"'\"+str(st)+\"'\"+' '\n",
        "    cursor.execute(postgreSQL_select_Query)\n",
        "    records = cursor.fetchall()\n",
        "    column_list = [i.name for i in cursor.description]\n",
        "    globals()[f\"{st}\"] = pd.DataFrame(records,columns=column_list)\n",
        "#     globals()[f\"{st}\"] = history_file[history_file[\"state\"]==st]\n",
        "#     globals()[f\"{st}\"].reset_index(drop=True,inplace = True)\n",
        "        \n",
        "connection.close()\n",
        "cursor.close()  \n",
        "print(\"\\n All the states taken and extracted state file from DB\")\n",
        "print(\"\\n states ---> \",state)\n"
      ],
      "id": "common-pollution",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Taking state name for file name --->   Master Leads | Tom Jervis sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Susan Marcrie sheet name --> ENRICHMENT\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Thom Dallman sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Kevin Sigstad sheet name --> ENRICHMENT 2\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Lindsay Sanger sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Curtis Johnson and Ahmad Essawy sheet name --> Enrichment (Elastic)\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Beth Scofield sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Brian Kwilosz sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Chuck Fazio sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Kristin Petersen (John Adams) sheet name --> ENRICHMENT -NOV 8 Elastic\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Kevin Yoder sheet name --> Enrichment (Nov 8 ES)\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Anton Usaj sheet name --> ENRICHMENT\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Paul Katrivanos sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | William Ellibee sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Carl Stratton sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Katie Hardman sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Sherry Davidson sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            "Taking state name for file name --->   Master Leads | Justin Reed sheet name --> Enrichment\n",
            "Taking office_state as state \n",
            "\n",
            " All the states taken and extracted state file from DB\n",
            "\n",
            " states --->  ['FL', 'NJ', 'ID', 'NV', 'AZ', 'IL', 'MI', 'CO', 'MD', 'NC', 'KS', 'MO', 'WA', 'OR', 'CA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "documented-yeast",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e457d536-fa6e-46bc-8f37-9f606f8410b8"
      },
      "source": [
        "df0.columns"
      ],
      "id": "documented-yeast",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'full_name', 'zip', 'cell', 'email', 'brand', 'position',\n",
              "       'office_name', 'office_address', 'office_city', 'office_state',\n",
              "       'office_zip', 'first_name', 'last_name', 'license_id'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "exact-chaos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f1119e-2c92-48a7-f000-44d7e7288f56"
      },
      "source": [
        "#For Matching Mobile number using Names and emails\n",
        "\n",
        "\n",
        "reject_no = int(input(\"Enter how many files you want to reject \"))\n",
        "\n",
        "reject_files_no = []\n",
        "if reject_no != 0:\n",
        "    for reject in range(reject_no):\n",
        "        reject_file = int(input(\"Enter the number of the file : \"))\n",
        "        if reject_file != 0:\n",
        "            if reject_file-1 not in reject_files_no:\n",
        "                reject_files_no.append(reject_file-1)\n",
        "\n",
        "for url in range(len(urls)):\n",
        "    \n",
        "    if url in reject_files_no:\n",
        "      continue\n",
        "      \n",
        "    Db_found_index = []\n",
        "    \n",
        "    globals()[f\"df{url}\"][\"Full_Name\"] = None\n",
        "    globals()[f\"df{url}\"][\"Found_Mobile\"] = None\n",
        "    globals()[f\"df{url}\"][\"Assign\"]  = None \n",
        "    #globals()[f\"df{url}\"][\"Comments\"]  = None \n",
        "    \n",
        "    print(\"\\n ************************************************************************** \\n\")\n",
        "    print(\"Matching for file name : \",file_name[url], \"sheet name -->\", sheet_name[url])\n",
        "    \n",
        "    first_name , last_name  = res.Full_name_creator(globals()[f\"df{url}\"].columns)\n",
        "    Agent_Name = ''\n",
        "    \n",
        "    if len(first_name) > 0  and len(last_name) > 0:\n",
        "        pass\n",
        "    else:\n",
        "        Agent_Name = res.agent_name_finder(globals()[f\"df{url}\"].columns)\n",
        "    \n",
        "    if len(Agent_Name) > 0:\n",
        "        globals()[f\"df{url}\"] = res.Name_checker(globals()[f\"df{url}\"],Agent_Name)\n",
        "    \n",
        "    full_name = res.full_name_finder(globals()[f\"df{url}\"].columns)\n",
        "    state =  res.state_finder(globals()[f\"df{url}\"].columns)\n",
        "    first_name, last_name = res.Full_name_creator(globals()[f\"df{url}\"].columns)\n",
        "    email = res.emaiL_finder(globals()[f\"df{url}\"].columns)\n",
        "    license = res.license_finder(globals()[f\"df{url}\"].columns)\n",
        "    Zip = res.zip_finder(globals()[f\"df{url}\"].columns)\n",
        "    \n",
        "    if len(state) > 0:\n",
        "      if len(email) > 0: #\n",
        "          #globals()[f\"df{url}\"][\"Found_Mobile\"] = globals()[f\"df{url}\"].apply(lambda x: finding_mobile_email(x[email],x[state],x[\"Found_Mobile\"],x[Zip]), axis=1)\n",
        "          globals()[f\"df{url}\"][\"Found_Mobile\"] = globals()[f\"df{url}\"].apply(lambda x: finding_mobile_email(x[email],x[state],x[\"Found_Mobile\"]), axis=1)\n",
        "\n",
        "\n",
        "      if len(first_name) > 0 and len(last_name) > 0: #Extracting  concatenated Name [first name & last name]\n",
        "          \n",
        "          globals()[f\"df{url}\"][\"Full_Name\"] = globals()[f\"df{url}\"][first_name] +\" \"+ globals()[f\"df{url}\"][last_name]\n",
        "          #globals()[f\"df{url}\"][\"Found_Mobile\"] = globals()[f\"df{url}\"].apply(lambda x: finding_mobile_name(x[\"Full_Name\"],x[state],x[\"Found_Mobile\"],x[Zip]), axis=1)\n",
        "          globals()[f\"df{url}\"][\"Found_Mobile\"] = globals()[f\"df{url}\"].apply(lambda x: finding_mobile_name(x[\"Full_Name\"],x[state],x[\"Found_Mobile\"]), axis=1)\n",
        "\n",
        "\n",
        "              \n",
        "      if len(full_name) > 0: #Matching \n",
        "          \n",
        "          #globals()[f\"df{url}\"][\"Found_Mobile\"] = globals()[f\"df{url}\"].apply(lambda x: finding_mobile_name(x[full_name],x[state],x[\"Found_Mobile\"],x[Zip]), axis=1)\n",
        "          globals()[f\"df{url}\"][\"Found_Mobile\"] = globals()[f\"df{url}\"].apply(lambda x: finding_mobile_name(x[full_name],x[state],x[\"Found_Mobile\"]), axis=1)\n",
        "\n",
        "\n",
        "              \n",
        "      \n",
        "      Db_found_index = globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"Found_Mobile\"].notna()].index\n",
        "      \n",
        "      if len(Db_found_index) > 0:\n",
        "          globals()[f\"df{url}\"].loc[Db_found_index,\"Assign\"] = \"Matched From DB\"\n",
        "\n",
        "      \n",
        "      globals()[f\"df{url}\"] = res.license_count(globals()[f\"df{url}\"],\"Found_Mobile\")\n",
        "      \n",
        "      \n",
        "      if len(license)>0:\n",
        "          \n",
        "          globals()[f\"df{url}\"] = res.license_count(globals()[f\"df{url}\"],license)\n",
        "          \n",
        "          globals()[f\"df{url}\"] = res.license_count(globals()[f\"df{url}\"],\"Found_Mobile\")\n",
        "          \n",
        "          globals()[f\"df{url}\"] = res.duplicate_check(globals()[f\"df{url}\"])\n",
        "          #globals()[f\"df{url}\"] = res.comment(globals()[f\"df{url}\"])\n",
        "\n",
        "          globals()[f\"df{url}\"].drop(['license_id_count','Found_Mobile_count'],axis= 1 , inplace= True)\n",
        "          \n",
        "          \n",
        "\n",
        "    \n",
        "    "
      ],
      "id": "exact-chaos",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter how many files you want to reject 0\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Tom Jervis sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Susan Marcrie sheet name --> ENRICHMENT\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Thom Dallman sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Kevin Sigstad sheet name --> ENRICHMENT 2\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Lindsay Sanger sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Curtis Johnson and Ahmad Essawy sheet name --> Enrichment (Elastic)\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Beth Scofield sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Brian Kwilosz sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Chuck Fazio sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Kristin Petersen (John Adams) sheet name --> ENRICHMENT -NOV 8 Elastic\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Kevin Yoder sheet name --> Enrichment (Nov 8 ES)\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Anton Usaj sheet name --> ENRICHMENT\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Paul Katrivanos sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | William Ellibee sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Carl Stratton sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Katie Hardman sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Sherry Davidson sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n",
            "\n",
            " ************************************************************************** \n",
            "\n",
            "Matching for file name :  Master Leads | Justin Reed sheet name --> Enrichment\n",
            "Taking full_name as full name \n",
            "Taking office_state as state \n",
            "Taking first_name as First name\n",
            "Taking last_name as Last name\n",
            "Taking email as Email\n",
            "Taking  license_id as license\n",
            "Taking  zip as zip\n",
            "Taking  office_zip as zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "certain-clock"
      },
      "source": [
        "### To Reject the unwanted files "
      ],
      "id": "certain-clock"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "latter-howard",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5e5d09-783f-4425-ef99-8ab455dc2c4f"
      },
      "source": [
        "#### To create report of what matched from the DB \n",
        "for url in range(len(urls)):\n",
        "\n",
        "    try:\n",
        "      existing_index = globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"cell\"].notna()].index\n",
        "      if len(existing_index) > 0:\n",
        "          globals()[f\"df{url}\"].loc[existing_index,\"Assign\"] = \"Existing value present\"\n",
        "    except:\n",
        "      existing_index = []\n",
        "      pass\n",
        "    \n",
        "    blank_index = globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"Assign\"].isna()].index\n",
        "    print(\"\\n************* \"+file_name[url]+\" ************ File NO :\",url+1,\"\\n\")\n",
        "    \n",
        "    Total_count = len(globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"Found_Mobile\"].notna()])\n",
        "    Found_count = len(globals()[f\"df{url}\"][(globals()[f\"df{url}\"][\"Found_Mobile\"] !=\"Not Found\") & (globals()[f\"df{url}\"][\"Found_Mobile\"].notna())])\n",
        "    Not_Found = len(globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"Found_Mobile\"]==\"Not Found\"])\n",
        "    print(\"Existing value count : \", len(existing_index))\n",
        "    print(\"Found Count : \", Found_count)\n",
        "    print(\"Not Found Count : \",Not_Found)\n",
        "    print(\"Total count[Found + Not Found] :\", Total_count)\n",
        "    \n",
        "    print(len(blank_index),\"Blanks left\")\n",
        "    \n",
        "reject_no = int(input(\"Enter how many files you want to reject \"))\n",
        "\n",
        "reject_files_no = []\n",
        "if reject_no != 0:\n",
        "    for reject in range(reject_no):\n",
        "        reject_file = int(input(\"Enter the number of the file : \"))\n",
        "        if reject_file != 0:\n",
        "            if reject_file-1 not in reject_files_no:\n",
        "                reject_files_no.append(reject_file-1)"
      ],
      "id": "latter-howard",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "************* Master Leads | Tom Jervis ************ File NO : 1 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  46\n",
            "Not Found Count :  698\n",
            "Total count[Found + Not Found] : 744\n",
            "780 Blanks left\n",
            "\n",
            "************* Master Leads | Susan Marcrie ************ File NO : 2 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  3\n",
            "Not Found Count :  1457\n",
            "Total count[Found + Not Found] : 1460\n",
            "81 Blanks left\n",
            "\n",
            "************* Master Leads | Thom Dallman ************ File NO : 3 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  0\n",
            "Not Found Count :  1191\n",
            "Total count[Found + Not Found] : 1191\n",
            "47 Blanks left\n",
            "\n",
            "************* Master Leads | Kevin Sigstad ************ File NO : 4 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  1\n",
            "Not Found Count :  1007\n",
            "Total count[Found + Not Found] : 1008\n",
            "0 Blanks left\n",
            "\n",
            "************* Master Leads | Lindsay Sanger ************ File NO : 5 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  679\n",
            "Not Found Count :  26\n",
            "Total count[Found + Not Found] : 705\n",
            "3024 Blanks left\n",
            "\n",
            "************* Master Leads | Curtis Johnson and Ahmad Essawy ************ File NO : 6 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  0\n",
            "Not Found Count :  4893\n",
            "Total count[Found + Not Found] : 4893\n",
            "0 Blanks left\n",
            "\n",
            "************* Master Leads | Beth Scofield ************ File NO : 7 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  3\n",
            "Not Found Count :  2558\n",
            "Total count[Found + Not Found] : 2561\n",
            "0 Blanks left\n",
            "\n",
            "************* Master Leads | Brian Kwilosz ************ File NO : 8 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  56\n",
            "Not Found Count :  340\n",
            "Total count[Found + Not Found] : 396\n",
            "819 Blanks left\n",
            "\n",
            "************* Master Leads | Chuck Fazio ************ File NO : 9 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  0\n",
            "Not Found Count :  6503\n",
            "Total count[Found + Not Found] : 6503\n",
            "0 Blanks left\n",
            "\n",
            "************* Master Leads | Kristin Petersen (John Adams) ************ File NO : 10 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  18\n",
            "Not Found Count :  1324\n",
            "Total count[Found + Not Found] : 1342\n",
            "908 Blanks left\n",
            "\n",
            "************* Master Leads | Kevin Yoder ************ File NO : 11 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  16\n",
            "Not Found Count :  218\n",
            "Total count[Found + Not Found] : 234\n",
            "1181 Blanks left\n",
            "\n",
            "************* Master Leads | Anton Usaj ************ File NO : 12 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  78\n",
            "Not Found Count :  2686\n",
            "Total count[Found + Not Found] : 2764\n",
            "4188 Blanks left\n",
            "\n",
            "************* Master Leads | Paul Katrivanos ************ File NO : 13 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  123\n",
            "Not Found Count :  116\n",
            "Total count[Found + Not Found] : 239\n",
            "3061 Blanks left\n",
            "\n",
            "************* Master Leads | William Ellibee ************ File NO : 14 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  46\n",
            "Not Found Count :  1802\n",
            "Total count[Found + Not Found] : 1848\n",
            "488 Blanks left\n",
            "\n",
            "************* Master Leads | Carl Stratton ************ File NO : 15 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  765\n",
            "Not Found Count :  74\n",
            "Total count[Found + Not Found] : 839\n",
            "6667 Blanks left\n",
            "\n",
            "************* Master Leads | Katie Hardman ************ File NO : 16 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  219\n",
            "Not Found Count :  0\n",
            "Total count[Found + Not Found] : 219\n",
            "2144 Blanks left\n",
            "\n",
            "************* Master Leads | Sherry Davidson ************ File NO : 17 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  161\n",
            "Not Found Count :  2336\n",
            "Total count[Found + Not Found] : 2497\n",
            "1526 Blanks left\n",
            "\n",
            "************* Master Leads | Justin Reed ************ File NO : 18 \n",
            "\n",
            "Existing value count :  0\n",
            "Found Count :  193\n",
            "Not Found Count :  28\n",
            "Total count[Found + Not Found] : 221\n",
            "2586 Blanks left\n",
            "Enter how many files you want to reject 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgpivSiQwzvj"
      },
      "source": [
        "#Automate file Allocation with Manual Count\n",
        "for url in range(len(urls)):\n",
        "    \n",
        "\n",
        "    try:\n",
        "        existing_index = globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"cell\"].notna()].index\n",
        "        if len(existing_index) > 0:\n",
        "            globals()[f\"df{url}\"].loc[existing_index,\"Assign\"] = \"Existing Number present\"\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    if url in reject_files_no:\n",
        "        continue\n",
        "\n",
        "    print(\"Assigning in the file no : \",url,\" file name --> \", file_name[url], \" sheet name : \" , sheet_name[url])\n",
        "    print(\"Total Blanks left in this file \", len(blank_index))\n",
        "    blank_index = globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"Assign\"].isna()].index\n",
        "\n",
        "    globals()[f\"df{url}\"] = res.Automate_File_Allocation(globals()[f\"df{url}\"])"
      ],
      "id": "cgpivSiQwzvj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sophisticated-syndrome",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd2265f-d0f6-4d97-fe63-829492ced156"
      },
      "source": [
        "# #FOR AUTO ASSIGN\n",
        "\n",
        "# person = []    #edit  \n",
        "# person_count = []\n",
        "# count = 0\n",
        "# remaining_person_halfday = []\n",
        "# remaining_person_count_halfday = []\n",
        "# get_input = 1\n",
        "\n",
        "\n",
        "# for url in range(len(urls)):\n",
        "\n",
        "#     try:\n",
        "#       existing_index = globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"cell\"].notna()].index\n",
        "#       if len(existing_index) > 0:\n",
        "#           globals()[f\"df{url}\"].loc[existing_index,\"Assign\"] = \"Existing value present\"\n",
        "#     except:\n",
        "#       pass\n",
        "    \n",
        "#     if url in reject_files_no:\n",
        "#         continue\n",
        "    \n",
        "    \n",
        "#     full_day  = 0\n",
        "#     half_day = 0\n",
        "#     get_input = 1\n",
        "#     print(\"\\n****************************************************************************\\n\")\n",
        "    \n",
        "   \n",
        "#     blank_index = globals()[f\"df{url}\"][globals()[f\"df{url}\"][\"Assign\"].isna()].index\n",
        "    \n",
        "    \n",
        "#     print(\"Assigning in the file no : \",url,\" file name --> \", file_name[url], \" sheet name : \" , sheet_name[url])\n",
        "#     print(\"Total Blanks left in this file \", len(blank_index))\n",
        "#     file_count = len(blank_index)\n",
        "    \n",
        "#     if file_count ==  0:\n",
        "#         continue\n",
        "#     #****************************************input Full day*********************************************\n",
        "\n",
        "#     analyst_name_fullday = []\n",
        "    \n",
        "#     if len(person) != 0 :\n",
        "        \n",
        "#         analyst_name_fullday.extend(person)\n",
        "#         full_day = (len(person)-1)*500 + (500-person_count[0])\n",
        "\n",
        "#         if globals()[f\"df{url}\"].shape[0] >= (len(person)-1)*500 + (500-person_count[0]):\n",
        "            \n",
        "#             get_input = 1\n",
        "            \n",
        "            \n",
        "#         else:\n",
        "            \n",
        "#             get_input = 0\n",
        "            \n",
        "#     if len(remaining_person_halfday) != 0 :\n",
        "#         half_day = (len(remaining_person_halfday)-1)*250 + (250 - remaining_person_count_halfday[0])\n",
        "        \n",
        "        \n",
        "#     if file_count > full_day + half_day:\n",
        "#         get_input = 1\n",
        "#         if full_day + half_day != 0:\n",
        "#             print(full_day + half_day , \"Records will be assigned\",person[:],remaining_person_halfday[:])\n",
        "#             print(file_count - (full_day + half_day), \"Records only left\")\n",
        "#     else:\n",
        "#         get_input = 0\n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "#     try:\n",
        "        \n",
        "#         if get_input == 1:\n",
        "            \n",
        "#             no_analyst_fullday = int(input(\"Enter the number of person are going to work for full day : \"))\n",
        "            \n",
        "#         else:\n",
        "            \n",
        "#             no_analyst_fullday = 0\n",
        "            \n",
        "#     except:\n",
        "        \n",
        "#         print(\"\\nEnter the valid number\")\n",
        "#         if get_input == 1:\n",
        "#             no_analyst_fullday = int(input(\"Enter the number of person are going to work for full day : \"))\n",
        "#         else:\n",
        "#             no_analyst_fullday = 0\n",
        "            \n",
        "#     if no_analyst_fullday > 0:\n",
        "        \n",
        "#         print(\"Enter the name of the people who are going to work for Full day\")\n",
        "#         for person_no in range(no_analyst_fullday):\n",
        "#             name = str(input(str(person_no+1)+\" Enter the Name :\"))\n",
        "#             analyst_name_fullday.append(name)\n",
        "#         print(\"\\n\")\n",
        "            \n",
        "  \n",
        "    \n",
        "#     #****************************************Input half day*******************************************************\n",
        "    \n",
        "#     analyst_name_halfday = []\n",
        "    \n",
        "#     if len(remaining_person_halfday) != 0 :\n",
        "#         analyst_name_halfday.extend(remaining_person_halfday)\n",
        "        \n",
        "        \n",
        "#     try:\n",
        "#         if get_input == 1:\n",
        "\n",
        "#             no_analyst_halfday = int(input(\"Enter the number of person are going to work for half day  : \"))\n",
        "#         else:\n",
        "#             no_analyst_halfday = 0\n",
        "        \n",
        "#     except:\n",
        "#         print(\"Enter the valid input \")\n",
        "        \n",
        "#         if get_input == 1:\n",
        "#             no_analyst_halfday = int(input(\"Enter the number of person are going to work for half day : \"))\n",
        "            \n",
        "#         else:\n",
        "#             no_analyst_halfday = 0\n",
        "\n",
        "        \n",
        "#     if no_analyst_halfday > 0:\n",
        "#         print(\"Enter the name of the people who are going to work for half day \")\n",
        "#         for person_no in range(no_analyst_halfday):\n",
        "#             name = str(input(str(person_no+1)+\" Enter the Name :\"))\n",
        "#             analyst_name_halfday.append(name)\n",
        "#         print(\"\\n\")\n",
        "    \n",
        "    \n",
        "    \n",
        "#     #*****************************************************Full Day Assign*******************************************        \n",
        "\n",
        "\n",
        "#     if len(analyst_name_fullday) != 0:\n",
        "        \n",
        "        \n",
        "#         for name_no in range(len(analyst_name_fullday)):\n",
        "            \n",
        "#             if len(person) != 0 and name_no == 0 :\n",
        "                \n",
        "#                 count = person_count[0]\n",
        "                \n",
        "#             else:\n",
        "                \n",
        "#                 count = 0\n",
        "                \n",
        "#             globals()[f\"df{url}\"],count,status = res.assign(globals()[f\"df{url}\"],count, analyst_name_fullday[name_no])\n",
        "            \n",
        "#             print(count, \"Assigned for \", analyst_name_fullday[name_no] )\n",
        "            \n",
        "            \n",
        "#             if status == 'done':\n",
        "                \n",
        "                \n",
        "#                 print(\"There is no blank left\")\n",
        "                \n",
        "#                 #print(count, \"Assigned for \", analyst_name_fullday[name_no] )\n",
        "                \n",
        "#                 print(500-count, \"will be assigned in next file for \", analyst_name_fullday[name_no])\n",
        "\n",
        "#                 if count < 500:\n",
        "#                     if analyst_name_fullday[name_no] not in person:\n",
        "#                         person.append(analyst_name_fullday[name_no])\n",
        "#                         person_count.append(count)\n",
        "                    \n",
        "#                     if name_no == 0:\n",
        "#                         person_count[0] = count\n",
        "                        \n",
        "                    \n",
        "#                 if url == len(urls) - 1:\n",
        "\n",
        "#                     if len(person) != 0:\n",
        "                        \n",
        "#                         print(person[:], \"These persons are still remaining\")\n",
        "            \n",
        "#             if status != \"done\":\n",
        "#                 person = []\n",
        "#                 person_count = []\n",
        "                \n",
        "                \n",
        "\n",
        "#         #*******************************************************Half Day Assign*****************************************        \n",
        "\n",
        "\n",
        "#     if len(analyst_name_halfday) != 0:\n",
        "        \n",
        "        \n",
        "#         for name_no in range(len(analyst_name_halfday)):\n",
        "            \n",
        "#             if len(remaining_person_halfday) != 0 and name_no == 0 :\n",
        "                \n",
        "#                 count = remaining_person_count_halfday[0]\n",
        "                \n",
        "#             else:\n",
        "                \n",
        "#                 count = 0\n",
        "                \n",
        "#             globals()[f\"df{url}\"],count,status = res.assign_half(globals()[f\"df{url}\"],count, analyst_name_halfday[name_no])\n",
        "            \n",
        "#             print(count, \"Assigned for \", analyst_name_halfday[name_no] )\n",
        "            \n",
        "            \n",
        "#             if status == 'done':\n",
        "                \n",
        "                \n",
        "#                 print(\"There is no blank left\")\n",
        "                \n",
        "#                 #print(count, \"Assigned for \", analyst_name_halfday[name_no] )\n",
        "                \n",
        "#                 print(250-count, \"will be assigned in next file for\", analyst_name_halfday[name_no])\n",
        "\n",
        "#                 if count < 250:\n",
        "#                     if analyst_name_halfday[name_no] not in person:\n",
        "#                         remaining_person_halfday.append(analyst_name_halfday[name_no])\n",
        "#                         remaining_person_count_halfday.append(count)\n",
        "#                     if name_no == 0:\n",
        "#                         remaining_person_count_halfday[0] = count\n",
        "                        \n",
        "                    \n",
        "#                 if url == len(urls) - 1:\n",
        "\n",
        "#                     if len(remaining_person_halfday) != 0:\n",
        "                        \n",
        "#                         print(remaining_person_halfday[:], \"These persons are still remaining\")\n",
        "            \n",
        "#             if status != \"done\":\n",
        "#                 remaining_person_halfday = []\n",
        "#                 remaining_person_count_halfday = []\n",
        "                \n",
        "#     try:\n",
        "#         if globals()[f\"df{url}\"][\"Assign\"].isna().sum() > 0:\n",
        "#             print(globals()[f\"df{url}\"][\"Assign\"].isna().sum(), \"still left in this file\")\n",
        "#     except:\n",
        "#         pass\n"
      ],
      "id": "sophisticated-syndrome",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "****************************************************************************\n",
            "\n",
            "Assigning in the file no :  0  file name -->  Master Leads | Jim Burton  sheet name :  ENRICHMENT TICKET (Elastic)\n",
            "Total Blanks left in this file  2588\n",
            "Enter the number of person are going to work for full day : 1\n",
            "Enter the name of the people who are going to work for Full day\n",
            "1 Enter the Name :Melvin\n",
            "\n",
            "\n",
            "Enter the number of person are going to work for half day  : 0\n",
            "500 Assigned for  Melvin\n",
            "2088 still left in this file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latin-partnership"
      },
      "source": [
        "### To Export to Google sheets "
      ],
      "id": "latin-partnership"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "imported-creation",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "e5107d63-478d-40a7-b6ff-30c857ee92ed"
      },
      "source": [
        "#To export to google sheets\n",
        "\n",
        "albha = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"AA\",\"AB\",\"AC\"]\n",
        "for url in range(len(urls)):\n",
        "    \n",
        "    Data = globals()[f\"df{url}\"][[\"Full_Name\",\"Found_Mobile\",\"Assign\"]]\n",
        "    # na_index = Data[Data[\"Comments\"].isna()].index\n",
        "    # if len(na_index) > 0:\n",
        "    #     Data.loc[na_index,\"Comments\"] = None\n",
        "        \n",
        "    na_index = Data[Data[\"Full_Name\"].isna()].index\n",
        "    if len(na_index) > 0:\n",
        "        Data.loc[na_index,\"Full_Name\"] = None\n",
        "       \n",
        "    na_index = Data[Data[\"Found_Mobile\"].isna()].index\n",
        "    if len(na_index) > 0:\n",
        "        Data.loc[na_index,\"Found_Mobile\"] = None\n",
        "    \n",
        "    na_index = Data[Data[\"Assign\"].isna()].index\n",
        "    if len(na_index) > 0:\n",
        "        Data.loc[na_index,\"Assign\"] = None\n",
        "    \n",
        "    \n",
        "    sheet_data_list = []\n",
        "    for index in range(len(Data)):\n",
        "        sheet_data_list.append([str(Data.loc[index,'Full_Name']),str(Data.loc[index,'Found_Mobile']), str(Data.loc[index,'Assign'])])\n",
        "    \n",
        "\n",
        "\n",
        "    data = [['Full_Name', 'Found_Mobile', 'Assign']]\n",
        "    request = service.spreadsheets().values().append(spreadsheetId=spreadsheet_id[url], \n",
        "                                                     range=sheet_name[url]+\"!\"+albha[column_length[url]]+str(1)+\":\"+albha[column_length[url]+2]+str(1), valueInputOption=\"USER_ENTERED\", \n",
        "                                                     insertDataOption=\"OVERWRITE\", body={\"values\":data})\n",
        "\n",
        "    response = request.execute()\n",
        "    \n",
        "        \n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "    data = sheet_data_list\n",
        "    request = service.spreadsheets().values().append(spreadsheetId=spreadsheet_id[url], \n",
        "                                                     range=sheet_name[url]+\"!\"+albha[column_length[url]]+str(2)+\":\"+albha[column_length[url]+2]+str(2), valueInputOption=\"USER_ENTERED\", \n",
        "                                                     insertDataOption=\"OVERWRITE\", body={\"values\":data})\n",
        "\n",
        "    response = request.execute()"
      ],
      "id": "imported-creation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-65babd8b1f0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0malbha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"D\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"E\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"G\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"H\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"J\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"M\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"N\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"P\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Q\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"R\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"S\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"U\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"V\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AA\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AB\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AC\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"df{url}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Full_Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Found_Mobile\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'urls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BP32ASTmtd_"
      },
      "source": [
        ""
      ],
      "id": "2BP32ASTmtd_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generic-intent"
      },
      "source": [
        ""
      ],
      "id": "generic-intent",
      "execution_count": null,
      "outputs": []
    }
  ]
}